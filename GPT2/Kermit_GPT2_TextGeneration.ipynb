{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kermit_GPT2_TextGeneration.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ParkEunHyeok/Project_Kermit/blob/main/GPT2/Kermit_GPT2_TextGeneration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uls6fXiwQvWa",
        "outputId": "048b555c-6714-4097-b4b4-f9feb6e872c9"
      },
      "source": [
        "!pip install tqdm\n",
        "!pip install kobert-transformers==0.4.1\n",
        "!pip install kogpt2-transformers==0.3.0\n",
        "!pip install transformers==3.0.2\n",
        "!pip install torch\n",
        "!pip install tokenizers==0.8.1rc1\n",
        "!pip install kss"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.2)\n",
            "Requirement already satisfied: kobert-transformers==0.4.1 in /usr/local/lib/python3.7/dist-packages (0.4.1)\n",
            "Requirement already satisfied: transformers>=2.9.1 in /usr/local/lib/python3.7/dist-packages (from kobert-transformers==0.4.1) (3.0.2)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from kobert-transformers==0.4.1) (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.1.0->kobert-transformers==0.4.1) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers>=2.9.1->kobert-transformers==0.4.1) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.9.1->kobert-transformers==0.4.1) (4.62.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.9.1->kobert-transformers==0.4.1) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=2.9.1->kobert-transformers==0.4.1) (0.0.45)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers>=2.9.1->kobert-transformers==0.4.1) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=2.9.1->kobert-transformers==0.4.1) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers>=2.9.1->kobert-transformers==0.4.1) (21.0)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.9.1->kobert-transformers==0.4.1) (0.1.96)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.9.1->kobert-transformers==0.4.1) (0.8.1rc1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers>=2.9.1->kobert-transformers==0.4.1) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.9.1->kobert-transformers==0.4.1) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.9.1->kobert-transformers==0.4.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.9.1->kobert-transformers==0.4.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.9.1->kobert-transformers==0.4.1) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=2.9.1->kobert-transformers==0.4.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=2.9.1->kobert-transformers==0.4.1) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=2.9.1->kobert-transformers==0.4.1) (1.15.0)\n",
            "Requirement already satisfied: kogpt2-transformers==0.3.0 in /usr/local/lib/python3.7/dist-packages (0.3.0)\n",
            "Requirement already satisfied: tokenizers>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from kogpt2-transformers==0.3.0) (0.8.1rc1)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from kogpt2-transformers==0.3.0) (3.0.2)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from kogpt2-transformers==0.3.0) (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.1.0->kogpt2-transformers==0.3.0) (3.7.4.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->kogpt2-transformers==0.3.0) (0.0.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->kogpt2-transformers==0.3.0) (21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->kogpt2-transformers==0.3.0) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->kogpt2-transformers==0.3.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->kogpt2-transformers==0.3.0) (4.62.2)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->kogpt2-transformers==0.3.0) (0.1.96)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->kogpt2-transformers==0.3.0) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->kogpt2-transformers==0.3.0) (2019.12.20)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers>=3.0.0->kogpt2-transformers==0.3.0) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=3.0.0->kogpt2-transformers==0.3.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=3.0.0->kogpt2-transformers==0.3.0) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=3.0.0->kogpt2-transformers==0.3.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=3.0.0->kogpt2-transformers==0.3.0) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=3.0.0->kogpt2-transformers==0.3.0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=3.0.0->kogpt2-transformers==0.3.0) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=3.0.0->kogpt2-transformers==0.3.0) (7.1.2)\n",
            "Requirement already satisfied: transformers==3.0.2 in /usr/local/lib/python3.7/dist-packages (3.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (0.0.45)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (4.62.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (21.0)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (0.8.1rc1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (1.19.5)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (0.1.96)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.2) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2021.5.30)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.0.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: tokenizers==0.8.1rc1 in /usr/local/lib/python3.7/dist-packages (0.8.1rc1)\n",
            "Requirement already satisfied: kss in /usr/local/lib/python3.7/dist-packages (3.2.0)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (from kss) (1.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_NIHOQjPWdm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc412208-e4e9-4f74-db2a-602383995dd2"
      },
      "source": [
        "# 구글 드라이브 연결\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "path = \"gdrive/My Drive/Colab Notebooks/HelloNewWorld/gpt/\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import dataloader, Dataset\n",
        "from kogpt2_transformers import get_kogpt2_tokenizer, get_kogpt2_model"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA2ElX1QQXWf"
      },
      "source": [
        "# !python3 '/content/gdrive/My Drive/Colab Notebooks/HelloNewWorld/gpt/preprocess/training_data.py'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaOwgspT1sy-"
      },
      "source": [
        "class DialogKoGPT2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(DialogKoGPT2, self).__init__()\n",
        "    self.kogpt2 = get_kogpt2_model()\n",
        "\n",
        "  def generate(self,\n",
        "               input_ids,\n",
        "               do_sample=True,\n",
        "               max_length= 40,\n",
        "               top_p=0.92,\n",
        "               top_k=50,\n",
        "               temperature= 0.6,\n",
        "               no_repeat_ngram_size =None,\n",
        "               num_return_sequences=3,\n",
        "               early_stopping=False,\n",
        "               ):\n",
        "    return self.kogpt2.generate(input_ids,\n",
        "               do_sample=do_sample,\n",
        "               max_length=max_length,\n",
        "               top_p = top_p,\n",
        "               top_k=top_k,\n",
        "               temperature=temperature,\n",
        "               no_repeat_ngram_size= no_repeat_ngram_size,\n",
        "               num_return_sequences=num_return_sequences,\n",
        "               early_stopping = early_stopping,\n",
        "              )\n",
        "\n",
        "  def forward(self, input, labels = None):\n",
        "    if labels is not None:\n",
        "      outputs = self.kogpt2(input, labels=labels)\n",
        "    else:\n",
        "      outputs = self.kogpt2(input)\n",
        "\n",
        "    return outputs"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K30UojjknXLi"
      },
      "source": [
        "class WellnessAutoRegressiveDataset(Dataset):\n",
        "  \"\"\"Wellness Auto Regressive Dataset\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               file_path = path+\"data/wellness_dialog_for_autoregressive.txt\",\n",
        "               n_ctx = 1024\n",
        "               ):\n",
        "    self.file_path = file_path\n",
        "    self.data =[]\n",
        "    self.tokenizer = get_kogpt2_tokenizer()\n",
        "\n",
        "\n",
        "    bos_token_id = [self.tokenizer.bos_token_id]\n",
        "    eos_token_id = [self.tokenizer.eos_token_id]\n",
        "    pad_token_id = [self.tokenizer.pad_token_id]\n",
        "\n",
        "    file = open(self.file_path, 'r', encoding='utf-8')\n",
        "\n",
        "    while True:\n",
        "      line = file.readline()\n",
        "      if not line:\n",
        "        break\n",
        "      datas = line.split(\"\\t\")\n",
        "      index_of_words = bos_token_id +self.tokenizer.encode(datas[0]) + eos_token_id + bos_token_id + self.tokenizer.encode(datas[1][:-1])+ eos_token_id\n",
        "      pad_token_len = n_ctx - len(index_of_words)\n",
        "\n",
        "      index_of_words += pad_token_id * pad_token_len\n",
        "\n",
        "      self.data.append(index_of_words)\n",
        "\n",
        "    file.close()\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    item = self.data[index]\n",
        "    return item"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lzn7sY36nZ_u"
      },
      "source": [
        "dataset = WellnessAutoRegressiveDataset()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAVo-t80ncml",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9efe5534-f099-46ea-ebfa-e65a5c15502f"
      },
      "source": [
        "root_path=\"gdrive/My Drive/Colab Notebooks/HelloNewWorld/gpt\"\n",
        "data_path = f\"{root_path}/data/chatbot_wellness_dialog_for_autoregressive.txt\"\n",
        "checkpoint_path =f\"{root_path}/checkpoint\"\n",
        "load_ckpt_path = f\"{checkpoint_path}/kogpt2-wellnesee-auto-regressive-20210922.pth\"\n",
        "save_ckpt_path = f\"{checkpoint_path}/kogpt2-wellnesee-auto-regressive-20210922-add-chatbotdata.pth\"\n",
        "\n",
        "n_epoch = 2         # Num of Epoch\n",
        "batch_size = 2      # 배치 사이즈\n",
        "ctx = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device = torch.device(ctx)\n",
        "save_step = 100 # 학습 저장 주기\n",
        "learning_rate = 5e-5  # Learning Rate\n",
        "\n",
        "dataset= WellnessAutoRegressiveDataset(data_path)\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "model = DialogKoGPT2()\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "loss_fct = torch.nn.CrossEntropyLoss(ignore_index=3)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "losses =[]\n",
        "for epoch in range(n_epoch):\n",
        "    count = 0\n",
        "    with tqdm(total=len(train_loader), desc=f\"Train({epoch})\") as pbar:\n",
        "        for i, data in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            data = torch.stack(data)  # list of Tensor로 구성되어 있기 때문에 list를 stack을 통해 변환해준다.\n",
        "            data = data.transpose(1, 0)\n",
        "            data= data.to(ctx)\n",
        "\n",
        "            outputs = model(data, labels=data)\n",
        "            _, logits = outputs[:2]\n",
        "\n",
        "            # Shift so that tokens < n predict n\n",
        "            shift_logits = logits[..., :-1, :].contiguous()\n",
        "            shift_labels = data[..., 1:].contiguous()\n",
        "\n",
        "            loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            # if count % 10 == 0:\n",
        "            #     print('epoch no.{} train no.{}  loss = {}'.format(epoch, count + 1, loss))\n",
        "            if (count > 0 and count % save_step == 0) or (len(data) < batch_size):\n",
        "                torch.save({\n",
        "                    'epoch': epoch,\n",
        "                    'train_no': count,\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(), \n",
        "                    'loss': loss\n",
        "                }, save_ckpt_path)\n",
        "            count += 1\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix_str(f\"Loss: {loss.item():.3f} ({np.mean(losses):.3f})\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train(0):  85%|████████▍ | 11718/13840 [4:37:04<47:23,  1.34s/it, Loss: 2.698 (2.394)]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azWKtToZzBeu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}